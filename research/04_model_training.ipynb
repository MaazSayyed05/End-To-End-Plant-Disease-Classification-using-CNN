{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import  dataclass\n",
    "from pathlib import  Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Training:\n",
    "    root_dir: Path\n",
    "    model_path: Path\n",
    "    model_metrics_path: Path\n",
    "    data: Path\n",
    "    updated_model_path: Path\n",
    "    INPUT_SHAPE: list\n",
    "    BATCH_SIZE: int\n",
    "    SHUFFLE: bool\n",
    "    VALIDATION_SPLIT: float\n",
    "    LABEL_MODEL: str\n",
    "    EPOCHS: int\n",
    "    AUGMENTED: bool\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plant_disease_clf.utils.common import  create_directories, read_yaml\n",
    "from plant_disease_clf.constants import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager:\n",
    "    def __init__(self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_training_config(self):\n",
    "\n",
    "        self.config = self.config.model_training\n",
    "        self.params = self.params.resnet50\n",
    "\n",
    "        create_directories([self.config.root_dir])\n",
    "\n",
    "        return Training (\n",
    "            root_dir = Path(self.config.root_dir),\n",
    "            model_path = Path(self.config.model_path),\n",
    "            model_metrics_path = Path(self.config.model_metrics_path),\n",
    "            data = Path(self.config.data),\n",
    "            updated_model_path = Path(self.config.updated_model_path),\n",
    "            INPUT_SHAPE = self.params.INPUT_SHAPE,\n",
    "            BATCH_SIZE = self.params.BATCH_SIZE,\n",
    "            SHUFFLE = self.params.SHUFFLE,\n",
    "            VALIDATION_SPLIT = self.params.VALIDATION_SPLIT,\n",
    "            LABEL_MODEL = self.params.LABEL_MODEL,\n",
    "            EPOCHS = self.params.EPOCHS,\n",
    "            AUGMENTED = self.params.AUGMENTED\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from pathlib import Path\n",
    "from plant_disease_clf.logger import  logging\n",
    "from plant_disease_clf.exception import  CustomException\n",
    "\n",
    "from plant_disease_clf.utils.common import  save_json\n",
    "\n",
    "import tensorflow as tf\n",
    "from plant_disease_clf.pipeline.stage_03_prepare_callbacks import  CallbacksPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: Training):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_updated_model(self):\n",
    "        return tf.keras.models.load_model(self.config.updated_model_path)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            logging.info(f\"Training the model with the following config: {self.config}\")\n",
    "\n",
    "            callbacks = CallbacksPipeline()\n",
    "            callbacks_list = callbacks.main()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------\n",
    "            # train_data, val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "            #     directory = self.config.data,\n",
    "            #     labels = \"inferred\",\n",
    "            #     label_mode = self.config.LABEL_MODEL,\n",
    "            #     batch_size = self.config.BATCH_SIZE,\n",
    "            #     image_size = self.config.INPUT_SHAPE,\n",
    "            #     shuffle = self.config.SHUFFLE,\n",
    "            #     seed = 42,  #--------------------- add this for splitting the data\n",
    "            #     validation_split = self.config.VALIDATION_SPLIT,\n",
    "            #     subset = self.config.SUBSET,\n",
    "            #     interpolation = \"bilinear\",\n",
    "            # )\n",
    "            # train_data_samples = tf.data.experimental.cardinality(train_data).numpy()\n",
    "            # val_data_samples = tf.data.experimental.cardinality(val_data).numpy()\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------\n",
    "            data_generator_kwargs = dict(\n",
    "                rescale = 1./255,\n",
    "                validation_split = 0.20\n",
    "            )\n",
    "\n",
    "            data_flow_kwargs = dict(\n",
    "                target_size = self.config.INPUT_SHAPE[:-1],\n",
    "                batch_size = self.config.BATCH_SIZE,\n",
    "                interpolation = 'bilinear'\n",
    "            )\n",
    "\n",
    "\n",
    "            valid_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                **data_generator_kwargs\n",
    "            )\n",
    "\n",
    "            val_data = valid_data_gen.flow_from_directory(\n",
    "                directory = self.config.data,\n",
    "                class_mode = self.config.LABEL_MODEL,\n",
    "                shuffle = self.config.SHUFFLE,\n",
    "                seed = 42,  #--------------------- add this for splitting the data\n",
    "                subset = 'validation',\n",
    "                # interpolation = \"bilinear\",\n",
    "                **data_flow_kwargs\n",
    "            )\n",
    "\n",
    "            if self.config.AUGMENTED:\n",
    "                train_data_gen= tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rotation_range = 40,\n",
    "                    horizontal_flip = True,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    **data_generator_kwargs\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    **data_generator_kwargs\n",
    "                )\n",
    "\n",
    "            train_data = train_data_gen.flow_from_directory(\n",
    "                directory = self.config.data,\n",
    "                class_mode = self.config.LABEL_MODEL,\n",
    "                shuffle = True, ### \n",
    "                # seed = 42,  #--------------------- add this for splitting the data\n",
    "                subset = 'training',\n",
    "                # interpolation = \"bilinear\",\n",
    "                **data_flow_kwargs\n",
    "            )\n",
    "\n",
    "            model = self.get_updated_model()\n",
    "\n",
    "            print(callbacks_list)\n",
    "            print(model.summary())\n",
    "\n",
    "            # history = model.fit(\n",
    "            #     train_data,\n",
    "            #     epochs = self.config.EPOCHS,\n",
    "            #     validation_data = val_data,\n",
    "            #     callbacks = callbacks_list\n",
    "            # )\n",
    "\n",
    "            \n",
    "            self.steps_per_epoch = train_data.samples // self.config.BATCH_SIZE\n",
    "\n",
    "            self.validation_steps = val_data.samples // self.config.BATCH_SIZE \n",
    "\n",
    "\n",
    "            history = model.fit(\n",
    "                train_data,\n",
    "                steps_per_epoch = self.steps_per_epoch,\n",
    "                epochs = self.config.EPOCHS,\n",
    "                validation_data = val_data,\n",
    "                validation_steps = self.validation_steps,\n",
    "                callbacks = callbacks_list\n",
    "            )\n",
    "\n",
    "            # tf.keras.models.save_model(model, self.config.model_path)\n",
    "            # save_json(self.config.model_metrics_path, history.history)\n",
    "            logging.info(\"Model training completed successfully\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Model training failed: {e}\")\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    config_manager = ConfigManager()\n",
    "    config = config_manager.get_model_training_config()\n",
    "    model_training = ModelTraining(config)\n",
    "    model_training.train()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plants",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
